{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72838c38-9b54-4967-a94c-5bca18ef2fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model LogisticRegression with feature selection...\n",
      "Selected Features: Index(['District_Lakhisarai', 'District_Madhepura', 'CropEstablishment_CT', 'Variety_HD_2985', 'Variety_HI_1563', 'Variety_PBW_154', 'SowingSchedule_T4', 'SowingSchedule_T5', 'HerbicideName_Metribuzin', 'HerbicideName_TOTAL'], dtype='object')\n",
      "Evaluating model SVC without feature selection...\n",
      "Evaluating model DecisionTreeClassifier without feature selection...\n",
      "Evaluating model RandomForestClassifier without feature selection...\n",
      "Evaluating model GradientBoostingClassifier without feature selection...\n",
      "Evaluating model AdaBoostClassifier without feature selection...\n",
      "Evaluating model GaussianNB without feature selection...\n",
      "Evaluating model KNeighborsClassifier without feature selection...\n",
      "Evaluating model Perceptron without feature selection...\n",
      "Model Evaluation Results:\n",
      "                        Model       AUC  Accuracy (CA)  F1-score  Precision    Recall       MCC\n",
      "0          LogisticRegression  0.752440       0.607229  0.563028   0.611763  0.607229  0.346452\n",
      "1                         SVC  0.883250       0.749933  0.744568   0.753308  0.749933  0.593792\n",
      "2      DecisionTreeClassifier  0.757101       0.689424  0.689432   0.689639  0.689424  0.503298\n",
      "3      RandomForestClassifier  0.908090       0.771084  0.769778   0.771344  0.771084  0.630562\n",
      "4  GradientBoostingClassifier  0.886784       0.751807  0.748617   0.752890  0.751807  0.597788\n",
      "5          AdaBoostClassifier  0.785572       0.628916  0.615330   0.633552  0.628916  0.384913\n",
      "6                  GaussianNB  0.663523       0.310040  0.232742   0.570041  0.310040  0.126439\n",
      "7        KNeighborsClassifier  0.872707       0.732262  0.731896   0.734453  0.732262  0.567988\n",
      "8                  Perceptron       NaN       0.598929  0.594406   0.595829  0.598929  0.350394\n",
      "\n",
      "Sorted by AUC:\n",
      "                        Model       AUC  Accuracy (CA)  F1-score  Precision    Recall       MCC\n",
      "3      RandomForestClassifier  0.908090       0.771084  0.769778   0.771344  0.771084  0.630562\n",
      "4  GradientBoostingClassifier  0.886784       0.751807  0.748617   0.752890  0.751807  0.597788\n",
      "1                         SVC  0.883250       0.749933  0.744568   0.753308  0.749933  0.593792\n",
      "7        KNeighborsClassifier  0.872707       0.732262  0.731896   0.734453  0.732262  0.567988\n",
      "5          AdaBoostClassifier  0.785572       0.628916  0.615330   0.633552  0.628916  0.384913\n",
      "2      DecisionTreeClassifier  0.757101       0.689424  0.689432   0.689639  0.689424  0.503298\n",
      "0          LogisticRegression  0.752440       0.607229  0.563028   0.611763  0.607229  0.346452\n",
      "6                  GaussianNB  0.663523       0.310040  0.232742   0.570041  0.310040  0.126439\n",
      "8                  Perceptron       NaN       0.598929  0.594406   0.595829  0.598929  0.350394\n",
      "Evaluating for State_UP: 0\n",
      "Evaluating model LogisticRegression for State_UP = 0...\n",
      "Evaluating model SVC for State_UP = 0...\n",
      "Evaluating model DecisionTreeClassifier for State_UP = 0...\n",
      "Evaluating model RandomForestClassifier for State_UP = 0...\n",
      "Evaluating model GradientBoostingClassifier for State_UP = 0...\n",
      "Evaluating model AdaBoostClassifier for State_UP = 0...\n",
      "Evaluating model GaussianNB for State_UP = 0...\n",
      "Evaluating model KNeighborsClassifier for State_UP = 0...\n",
      "Evaluating model Perceptron for State_UP = 0...\n",
      "Evaluating for State_UP: 1\n",
      "Evaluating model LogisticRegression for State_UP = 1...\n",
      "Evaluating model SVC for State_UP = 1...\n",
      "Evaluating model DecisionTreeClassifier for State_UP = 1...\n",
      "Evaluating model RandomForestClassifier for State_UP = 1...\n",
      "Evaluating model GradientBoostingClassifier for State_UP = 1...\n",
      "Evaluating model AdaBoostClassifier for State_UP = 1...\n",
      "Evaluating model GaussianNB for State_UP = 1...\n",
      "Evaluating model KNeighborsClassifier for State_UP = 1...\n",
      "Evaluating model Perceptron for State_UP = 1...\n",
      "Evaluating for State_Bihar: 0\n",
      "Evaluating model LogisticRegression for State_Bihar = 0...\n",
      "Evaluating model SVC for State_Bihar = 0...\n",
      "Evaluating model DecisionTreeClassifier for State_Bihar = 0...\n",
      "Evaluating model RandomForestClassifier for State_Bihar = 0...\n",
      "Evaluating model GradientBoostingClassifier for State_Bihar = 0...\n",
      "Evaluating model AdaBoostClassifier for State_Bihar = 0...\n",
      "Evaluating model GaussianNB for State_Bihar = 0...\n",
      "Evaluating model KNeighborsClassifier for State_Bihar = 0...\n",
      "Evaluating model Perceptron for State_Bihar = 0...\n",
      "Evaluating for State_Bihar: 1\n",
      "Evaluating model LogisticRegression for State_Bihar = 1...\n",
      "Evaluating model SVC for State_Bihar = 1...\n",
      "Evaluating model DecisionTreeClassifier for State_Bihar = 1...\n",
      "Evaluating model RandomForestClassifier for State_Bihar = 1...\n",
      "Evaluating model GradientBoostingClassifier for State_Bihar = 1...\n",
      "Evaluating model AdaBoostClassifier for State_Bihar = 1...\n",
      "Evaluating model GaussianNB for State_Bihar = 1...\n",
      "Evaluating model KNeighborsClassifier for State_Bihar = 1...\n",
      "Evaluating model Perceptron for State_Bihar = 1...\n",
      "Model Evaluation Results by Categorical Attributes:\n",
      "                         Model       AUC  Accuracy (CA)  F1-score  Precision    Recall       MCC Categorical Attribute  Category Value\n",
      "0           LogisticRegression  0.846498       0.710950  0.708458   0.711012  0.710950  0.531772              State_UP               0\n",
      "1                          SVC  0.891821       0.755245  0.751676   0.758305  0.755245  0.603358              State_UP               0\n",
      "2       DecisionTreeClassifier  0.771355       0.705208  0.705133   0.705608  0.705208  0.529829              State_UP               0\n",
      "3       RandomForestClassifier  0.910876       0.783985  0.783151   0.784771  0.783985  0.651393              State_UP               0\n",
      "4   GradientBoostingClassifier  0.899988       0.774847  0.773386   0.776037  0.774847  0.636166              State_UP               0\n",
      "5           AdaBoostClassifier  0.809523       0.657542  0.653694   0.660353  0.657542  0.438722              State_UP               0\n",
      "6                   GaussianNB  0.651261       0.294790  0.210172   0.616404  0.294790  0.130142              State_UP               0\n",
      "7         KNeighborsClassifier  0.884635       0.751181  0.750815   0.753233  0.751181  0.598923              State_UP               0\n",
      "8                   Perceptron       NaN       0.624744  0.622913   0.626074  0.624744  0.402663              State_UP               0\n",
      "9           LogisticRegression  0.822918       0.695021  0.680174   0.682546  0.695021  0.501261              State_UP               1\n",
      "10                         SVC  0.860575       0.732349  0.719542   0.728941  0.732349  0.561960              State_UP               1\n",
      "11      DecisionTreeClassifier  0.724770       0.658941  0.657389   0.660326  0.658941  0.451579              State_UP               1\n",
      "12      RandomForestClassifier  0.865977       0.731034  0.724007   0.724710  0.731034  0.561589              State_UP               1\n",
      "13  GradientBoostingClassifier  0.858085       0.709181  0.700616   0.702769  0.709181  0.525838              State_UP               1\n",
      "14          AdaBoostClassifier  0.816698       0.675600  0.662900   0.667414  0.675600  0.465742              State_UP               1\n",
      "15                  GaussianNB  0.738953       0.326898  0.261193   0.687209  0.326898  0.228666              State_UP               1\n",
      "16        KNeighborsClassifier  0.834088       0.682060  0.678945   0.683733  0.682060  0.479900              State_UP               1\n",
      "17                  Perceptron       NaN       0.625484  0.608760   0.602642  0.625484  0.388415              State_UP               1\n",
      "18          LogisticRegression  0.822918       0.695021  0.680174   0.682546  0.695021  0.501261           State_Bihar               0\n",
      "19                         SVC  0.860575       0.732349  0.719542   0.728941  0.732349  0.561960           State_Bihar               0\n",
      "20      DecisionTreeClassifier  0.724770       0.658941  0.657389   0.660326  0.658941  0.451579           State_Bihar               0\n",
      "21      RandomForestClassifier  0.865977       0.731034  0.724007   0.724710  0.731034  0.561589           State_Bihar               0\n",
      "22  GradientBoostingClassifier  0.858085       0.709181  0.700616   0.702769  0.709181  0.525838           State_Bihar               0\n",
      "23          AdaBoostClassifier  0.816698       0.675600  0.662900   0.667414  0.675600  0.465742           State_Bihar               0\n",
      "24                  GaussianNB  0.738953       0.326898  0.261193   0.687209  0.326898  0.228666           State_Bihar               0\n",
      "25        KNeighborsClassifier  0.834088       0.682060  0.678945   0.683733  0.682060  0.479900           State_Bihar               0\n",
      "26                  Perceptron       NaN       0.625484  0.608760   0.602642  0.625484  0.388415           State_Bihar               0\n",
      "27          LogisticRegression  0.846498       0.710950  0.708458   0.711012  0.710950  0.531772           State_Bihar               1\n",
      "28                         SVC  0.891821       0.755245  0.751676   0.758305  0.755245  0.603358           State_Bihar               1\n",
      "29      DecisionTreeClassifier  0.771355       0.705208  0.705133   0.705608  0.705208  0.529829           State_Bihar               1\n",
      "30      RandomForestClassifier  0.910876       0.783985  0.783151   0.784771  0.783985  0.651393           State_Bihar               1\n",
      "31  GradientBoostingClassifier  0.899988       0.774847  0.773386   0.776037  0.774847  0.636166           State_Bihar               1\n",
      "32          AdaBoostClassifier  0.809523       0.657542  0.653694   0.660353  0.657542  0.438722           State_Bihar               1\n",
      "33                  GaussianNB  0.651261       0.294790  0.210172   0.616404  0.294790  0.130142           State_Bihar               1\n",
      "34        KNeighborsClassifier  0.884635       0.751181  0.750815   0.753233  0.751181  0.598923           State_Bihar               1\n",
      "35                  Perceptron       NaN       0.624744  0.622913   0.626074  0.624744  0.402663           State_Bihar               1\n",
      "\n",
      "Sorted by AUC for Categorical Comparison:\n",
      "                         Model       AUC  Accuracy (CA)  F1-score  Precision    Recall       MCC Categorical Attribute  Category Value\n",
      "3       RandomForestClassifier  0.910876       0.783985  0.783151   0.784771  0.783985  0.651393              State_UP               0\n",
      "30      RandomForestClassifier  0.910876       0.783985  0.783151   0.784771  0.783985  0.651393           State_Bihar               1\n",
      "31  GradientBoostingClassifier  0.899988       0.774847  0.773386   0.776037  0.774847  0.636166           State_Bihar               1\n",
      "4   GradientBoostingClassifier  0.899988       0.774847  0.773386   0.776037  0.774847  0.636166              State_UP               0\n",
      "1                          SVC  0.891821       0.755245  0.751676   0.758305  0.755245  0.603358              State_UP               0\n",
      "28                         SVC  0.891821       0.755245  0.751676   0.758305  0.755245  0.603358           State_Bihar               1\n",
      "34        KNeighborsClassifier  0.884635       0.751181  0.750815   0.753233  0.751181  0.598923           State_Bihar               1\n",
      "7         KNeighborsClassifier  0.884635       0.751181  0.750815   0.753233  0.751181  0.598923              State_UP               0\n",
      "12      RandomForestClassifier  0.865977       0.731034  0.724007   0.724710  0.731034  0.561589              State_UP               1\n",
      "21      RandomForestClassifier  0.865977       0.731034  0.724007   0.724710  0.731034  0.561589           State_Bihar               0\n",
      "10                         SVC  0.860575       0.732349  0.719542   0.728941  0.732349  0.561960              State_UP               1\n",
      "19                         SVC  0.860575       0.732349  0.719542   0.728941  0.732349  0.561960           State_Bihar               0\n",
      "22  GradientBoostingClassifier  0.858085       0.709181  0.700616   0.702769  0.709181  0.525838           State_Bihar               0\n",
      "13  GradientBoostingClassifier  0.858085       0.709181  0.700616   0.702769  0.709181  0.525838              State_UP               1\n",
      "27          LogisticRegression  0.846498       0.710950  0.708458   0.711012  0.710950  0.531772           State_Bihar               1\n",
      "0           LogisticRegression  0.846498       0.710950  0.708458   0.711012  0.710950  0.531772              State_UP               0\n",
      "16        KNeighborsClassifier  0.834088       0.682060  0.678945   0.683733  0.682060  0.479900              State_UP               1\n",
      "25        KNeighborsClassifier  0.834088       0.682060  0.678945   0.683733  0.682060  0.479900           State_Bihar               0\n",
      "9           LogisticRegression  0.822918       0.695021  0.680174   0.682546  0.695021  0.501261              State_UP               1\n",
      "18          LogisticRegression  0.822918       0.695021  0.680174   0.682546  0.695021  0.501261           State_Bihar               0\n",
      "14          AdaBoostClassifier  0.816698       0.675600  0.662900   0.667414  0.675600  0.465742              State_UP               1\n",
      "23          AdaBoostClassifier  0.816698       0.675600  0.662900   0.667414  0.675600  0.465742           State_Bihar               0\n",
      "5           AdaBoostClassifier  0.809523       0.657542  0.653694   0.660353  0.657542  0.438722              State_UP               0\n",
      "32          AdaBoostClassifier  0.809523       0.657542  0.653694   0.660353  0.657542  0.438722           State_Bihar               1\n",
      "29      DecisionTreeClassifier  0.771355       0.705208  0.705133   0.705608  0.705208  0.529829           State_Bihar               1\n",
      "2       DecisionTreeClassifier  0.771355       0.705208  0.705133   0.705608  0.705208  0.529829              State_UP               0\n",
      "15                  GaussianNB  0.738953       0.326898  0.261193   0.687209  0.326898  0.228666              State_UP               1\n",
      "24                  GaussianNB  0.738953       0.326898  0.261193   0.687209  0.326898  0.228666           State_Bihar               0\n",
      "20      DecisionTreeClassifier  0.724770       0.658941  0.657389   0.660326  0.658941  0.451579           State_Bihar               0\n",
      "11      DecisionTreeClassifier  0.724770       0.658941  0.657389   0.660326  0.658941  0.451579              State_UP               1\n",
      "6                   GaussianNB  0.651261       0.294790  0.210172   0.616404  0.294790  0.130142              State_UP               0\n",
      "33                  GaussianNB  0.651261       0.294790  0.210172   0.616404  0.294790  0.130142           State_Bihar               1\n",
      "8                   Perceptron       NaN       0.624744  0.622913   0.626074  0.624744  0.402663              State_UP               0\n",
      "17                  Perceptron       NaN       0.625484  0.608760   0.602642  0.625484  0.388415              State_UP               1\n",
      "26                  Perceptron       NaN       0.625484  0.608760   0.602642  0.625484  0.388415           State_Bihar               0\n",
      "35                  Perceptron       NaN       0.624744  0.622913   0.626074  0.624744  0.402663           State_Bihar               1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option('display.width', 1000)  # Yatayda daha fazla alan kullanmasını sağlar\n",
    "\n",
    "# Read data\n",
    "dFrame = pd.read_excel(\"Data_processed.xlsx\")\n",
    "\n",
    "# Function to clean the data (fill missing values)\n",
    "def cleanData(dataFrame):\n",
    "    for column in dataFrame.columns:\n",
    "        if dataFrame[column].dtype in ['float64', 'int64']:\n",
    "            # Fill missing numeric values with mean\n",
    "            dataFrame[column] = dataFrame[column].fillna(dataFrame[column].mean()) \n",
    "        else:\n",
    "            # Fill missing categorical values with mode (most frequent value)\n",
    "            dataFrame[column] = dataFrame[column].fillna(dataFrame[column].mode()[0])  \n",
    "    return dataFrame\n",
    "\n",
    "# Function to convert categorical columns to numeric\n",
    "def changeToNumeric(dataFrame):\n",
    "    for col in dataFrame.columns:\n",
    "        if dataFrame[col].dtype not in ['float64', 'int64']:\n",
    "            # Convert categorical columns to numeric codes\n",
    "            dataFrame[col] = dataFrame[col].astype('category').cat.codes\n",
    "    return dataFrame\n",
    "\n",
    "# Function to perform feature selection using RFE (Recursive Feature Elimination)\n",
    "def featureSelection(model, X, y):\n",
    "    # Create the RFE model and select the top 10 features\n",
    "    rfe = RFE(model, n_features_to_select=10)\n",
    "    X_rfe = rfe.fit_transform(X, y)\n",
    "    selected_features = X.columns[rfe.support_]\n",
    "    return X_rfe, selected_features\n",
    "\n",
    "# Function to perform evaluation metrics calculation\n",
    "def evaluateModel(model, X, y):\n",
    "    # Stratified 5-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Metrics lists\n",
    "    auc_scores = []\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    mcc_scores = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]  # Use .iloc[] for row indexing\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]  # Use .iloc[] for row indexing\n",
    "        \n",
    "        # Feature Scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Train and Predict\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Handle Perceptron which doesn't have predict_proba\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_prob = model.predict_proba(X_test_scaled)  # for AUC\n",
    "        elif hasattr(model, 'decision_function'):\n",
    "            # Use decision_function for Perceptron as a proxy for probabilities\n",
    "            y_prob = model.decision_function(X_test_scaled)\n",
    "            # Convert to probabilities using a sigmoid function (for binary classification)\n",
    "            if len(np.unique(y)) == 2:\n",
    "                y_prob = 1 / (1 + np.exp(-y_prob))  # Sigmoid for binary classification\n",
    "            else:\n",
    "                # For multi-class classification, we can use the softmax function\n",
    "                # but let's skip AUC calculation for Perceptron in multi-class case\n",
    "                y_prob = None  # Set it to None, we will not calculate AUC for multi-class models with decision_function\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if y_prob is not None:  # Only calculate AUC if y_prob is available\n",
    "            try:\n",
    "                if len(np.unique(y)) > 2:  # Multi-class classification\n",
    "                    auc_score = roc_auc_score(y_test, y_prob, multi_class='ovr', average='macro')  # Multi-class AUC\n",
    "                else:  # Binary classification\n",
    "                    auc_score = roc_auc_score(y_test, y_prob)\n",
    "                auc_scores.append(auc_score)\n",
    "            except ValueError:\n",
    "                # If AUC calculation fails, append NaN (e.g., in case of empty predictions or other issues)\n",
    "                auc_scores.append(np.nan)\n",
    "        else:\n",
    "            auc_scores.append(np.nan)  # If no probability estimate, append NaN\n",
    "        \n",
    "        # Calculate other metrics\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "        precision_scores.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recall_scores.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        mcc_scores.append(matthews_corrcoef(y_test, y_pred))\n",
    "    \n",
    "    # Store the results for this model\n",
    "    results = {\n",
    "        \"Model\": model.__class__.__name__,\n",
    "        \"AUC\": np.nan if np.isnan(np.mean(auc_scores)) else np.mean(auc_scores),  # Handle NaN AUC\n",
    "        \"Accuracy (CA)\": np.mean(accuracy_scores),\n",
    "        \"F1-score\": np.mean(f1_scores),\n",
    "        \"Precision\": np.mean(precision_scores),\n",
    "        \"Recall\": np.mean(recall_scores),\n",
    "        \"MCC\": np.mean(mcc_scores)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    LogisticRegression(max_iter=10000, solver='liblinear', random_state=42),  # Increased max_iter and solver changed\n",
    "    SVC(random_state=42, probability=True),  # SVC with probability=True for AUC\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    AdaBoostClassifier(random_state=42, algorithm='SAMME'),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    Perceptron(random_state=42),\n",
    "]\n",
    "\n",
    "# Clean the data\n",
    "cleanedData = cleanData(dFrame)\n",
    "\n",
    "# Convert non-numeric data to numeric\n",
    "dFrame = changeToNumeric(cleanedData)\n",
    "\n",
    "# Split data into features and target\n",
    "X = dFrame.drop('GrainYield', axis=1)  # Assuming 'GrainYield' is the target column\n",
    "y = dFrame['GrainYield']\n",
    "\n",
    "# Initialize a list to store results\n",
    "all_results = []\n",
    "\n",
    "# Evaluate each model and store the results\n",
    "for model in models:\n",
    "    # Feature selection (RFE) for Logistic Regression (or any other model you choose)\n",
    "    if model.__class__.__name__ == 'LogisticRegression':\n",
    "        print(f\"Evaluating model {model.__class__.__name__} with feature selection...\")\n",
    "        X_rfe, selected_features = featureSelection(model, X, y)\n",
    "        print(f\"Selected Features: {selected_features}\")\n",
    "        # Evaluate on selected features\n",
    "        result_with_fs = evaluateModel(model, pd.DataFrame(X_rfe, columns=selected_features), y)\n",
    "        all_results.append(result_with_fs)\n",
    "    else:\n",
    "        print(f\"Evaluating model {model.__class__.__name__} without feature selection...\")\n",
    "        result = evaluateModel(model, X, y)\n",
    "        all_results.append(result)\n",
    "\n",
    "# Create a DataFrame to display results as a table\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Display the results\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Sort by any column, by AUC\n",
    "results_df = results_df.sort_values(by=\"AUC\", ascending=False)\n",
    "print(\"\\nSorted by AUC:\")\n",
    "print(results_df)\n",
    "\n",
    "# Kategorik Özellikler ile Karşılaştırma Fonksiyonu\n",
    "def evaluate_by_categorical_attributes(X, y, categorical_columns, models):\n",
    "    comparison_results = []\n",
    "    \n",
    "    # Kategorik özelliklerin kombinasyonları üzerinde dönüyoruz\n",
    "    for cat_column in categorical_columns:\n",
    "        # Categorical column'dan grup oluştur\n",
    "        grouped_data = X.groupby(cat_column)\n",
    "        \n",
    "        for group_name, group_data in grouped_data:\n",
    "            print(f\"Evaluating for {cat_column}: {group_name}\")\n",
    "            \n",
    "            # Veri kümesini, o kategoriye ait alt kümeye ayır\n",
    "            X_group = group_data\n",
    "            y_group = y[X_group.index]\n",
    "            \n",
    "            # Her model için değerlendirme yap\n",
    "            for model in models:\n",
    "                print(f\"Evaluating model {model.__class__.__name__} for {cat_column} = {group_name}...\")\n",
    "                \n",
    "                result = evaluateModel(model, X_group, y_group)\n",
    "                result['Categorical Attribute'] = cat_column\n",
    "                result['Category Value'] = group_name\n",
    "                comparison_results.append(result)\n",
    "    \n",
    "    # Sonuçları bir DataFrame'de topla\n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    return comparison_df\n",
    "\n",
    "# Kategorik özelliklere göre model değerlendirmesi yap\n",
    "categorical_columns = ['State_UP', 'State_Bihar']\n",
    "comparison_results_df = evaluate_by_categorical_attributes(X, y, categorical_columns, models)\n",
    "\n",
    "# Sonuçları görüntüle\n",
    "print(\"Model Evaluation Results by Categorical Attributes:\")\n",
    "print(comparison_results_df)\n",
    "\n",
    "# AUC'ye göre sıralama\n",
    "comparison_results_df_sorted = comparison_results_df.sort_values(by=\"AUC\", ascending=False)\n",
    "print(\"\\nSorted by AUC for Categorical Comparison:\")\n",
    "print(comparison_results_df_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4888516f-b51d-43dd-a5c4-9d6997f3611c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
