{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6377eab5-6ae1-4081-b51a-715165e15f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Results:\n",
      "                        Model       AUC  Accuracy (CA)  F1-score  Precision  \\\n",
      "0          LogisticRegression  0.835153       0.687015  0.683414   0.686735   \n",
      "1                         SVC  0.883250       0.749933  0.744568   0.753308   \n",
      "2      DecisionTreeClassifier  0.757101       0.689424  0.689432   0.689639   \n",
      "3      RandomForestClassifier  0.908090       0.771084  0.769778   0.771344   \n",
      "4  GradientBoostingClassifier  0.886784       0.751807  0.748617   0.752890   \n",
      "5          AdaBoostClassifier  0.785572       0.628916  0.615330   0.633552   \n",
      "6                  GaussianNB  0.663523       0.310040  0.232742   0.570041   \n",
      "7        KNeighborsClassifier  0.872707       0.732262  0.731896   0.734453   \n",
      "8                  Perceptron       NaN       0.598929  0.594406   0.595829   \n",
      "\n",
      "     Recall       MCC  \n",
      "0  0.687015  0.490297  \n",
      "1  0.749933  0.593792  \n",
      "2  0.689424  0.503298  \n",
      "3  0.771084  0.630562  \n",
      "4  0.751807  0.597788  \n",
      "5  0.628916  0.384913  \n",
      "6  0.310040  0.126439  \n",
      "7  0.732262  0.567988  \n",
      "8  0.598929  0.350394  \n",
      "\n",
      "Sorted by AUC:\n",
      "                        Model       AUC  Accuracy (CA)  F1-score  Precision  \\\n",
      "3      RandomForestClassifier  0.908090       0.771084  0.769778   0.771344   \n",
      "4  GradientBoostingClassifier  0.886784       0.751807  0.748617   0.752890   \n",
      "1                         SVC  0.883250       0.749933  0.744568   0.753308   \n",
      "7        KNeighborsClassifier  0.872707       0.732262  0.731896   0.734453   \n",
      "0          LogisticRegression  0.835153       0.687015  0.683414   0.686735   \n",
      "5          AdaBoostClassifier  0.785572       0.628916  0.615330   0.633552   \n",
      "2      DecisionTreeClassifier  0.757101       0.689424  0.689432   0.689639   \n",
      "6                  GaussianNB  0.663523       0.310040  0.232742   0.570041   \n",
      "8                  Perceptron       NaN       0.598929  0.594406   0.595829   \n",
      "\n",
      "     Recall       MCC  \n",
      "3  0.771084  0.630562  \n",
      "4  0.751807  0.597788  \n",
      "1  0.749933  0.593792  \n",
      "7  0.732262  0.567988  \n",
      "0  0.687015  0.490297  \n",
      "5  0.628916  0.384913  \n",
      "2  0.689424  0.503298  \n",
      "6  0.310040  0.126439  \n",
      "8  0.598929  0.350394  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# Read data\n",
    "dFrame = pd.read_excel(\"Data_processed.xlsx\")\n",
    "\n",
    "# Function to clean the data (fill missing values)\n",
    "def cleanData(dataFrame):\n",
    "    for column in dataFrame.columns:\n",
    "        if dataFrame[column].dtype in ['float64', 'int64']:\n",
    "            # Fill missing numeric values with mean\n",
    "            dataFrame[column] = dataFrame[column].fillna(dataFrame[column].mean()) \n",
    "        else:\n",
    "            # Fill missing categorical values with mode (most frequent value)\n",
    "            dataFrame[column] = dataFrame[column].fillna(dataFrame[column].mode()[0])  \n",
    "    return dataFrame\n",
    "\n",
    "# Function to convert categorical columns to numeric\n",
    "def changeToNumeric(dataFrame):\n",
    "    for col in dataFrame.columns:\n",
    "        if dataFrame[col].dtype not in ['float64', 'int64']:\n",
    "            # Convert categorical columns to numeric codes\n",
    "            dataFrame[col] = dataFrame[col].astype('category').cat.codes\n",
    "    return dataFrame\n",
    "\n",
    "# Function to perform feature selection using RFE (Recursive Feature Elimination)\n",
    "def featureSelection(model, X, y):\n",
    "    # Create the RFE model and select the top 10 features\n",
    "    rfe = RFE(model, n_features_to_select=10)\n",
    "    X_rfe = rfe.fit_transform(X, y)\n",
    "    selected_features = X.columns[rfe.support_]\n",
    "    return X_rfe, selected_features\n",
    "\n",
    "# Function to perform evaluation metrics calculation\n",
    "def evaluateModel(model, X, y):\n",
    "    # Stratified 5-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Metrics lists\n",
    "    auc_scores = []\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    mcc_scores = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]  # Use .iloc[] for row indexing\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]  # Use .iloc[] for row indexing\n",
    "        \n",
    "        # Feature Scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Train and Predict\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Handle Perceptron which doesn't have predict_proba\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_prob = model.predict_proba(X_test_scaled)  # for AUC\n",
    "        elif hasattr(model, 'decision_function'):\n",
    "            # Use decision_function for Perceptron as a proxy for probabilities\n",
    "            y_prob = model.decision_function(X_test_scaled)\n",
    "            # Convert to probabilities using a sigmoid function (for binary classification)\n",
    "            if len(np.unique(y)) == 2:\n",
    "                y_prob = 1 / (1 + np.exp(-y_prob))  # Sigmoid for binary classification\n",
    "            else:\n",
    "                # For multi-class classification, we can use the softmax function\n",
    "                # but let's skip AUC calculation for Perceptron in multi-class case\n",
    "                y_prob = None  # Set it to None, we will not calculate AUC for multi-class models with decision_function\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if y_prob is not None:  # Only calculate AUC if y_prob is available\n",
    "            try:\n",
    "                if len(np.unique(y)) > 2:  # Multi-class classification\n",
    "                    auc_score = roc_auc_score(y_test, y_prob, multi_class='ovr', average='macro')  # Multi-class AUC\n",
    "                else:  # Binary classification\n",
    "                    auc_score = roc_auc_score(y_test, y_prob)\n",
    "                auc_scores.append(auc_score)\n",
    "            except ValueError:\n",
    "                # If AUC calculation fails, append NaN (e.g., in case of empty predictions or other issues)\n",
    "                auc_scores.append(np.nan)\n",
    "        else:\n",
    "            auc_scores.append(np.nan)  # If no probability estimate, append NaN\n",
    "        \n",
    "        # Calculate other metrics\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "        precision_scores.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recall_scores.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        mcc_scores.append(matthews_corrcoef(y_test, y_pred))\n",
    "    \n",
    "    # Store the results for this model\n",
    "    results = {\n",
    "        \"Model\": model.__class__.__name__,\n",
    "        \"AUC\": np.nan if np.isnan(np.mean(auc_scores)) else np.mean(auc_scores),  # Handle NaN AUC\n",
    "        \"Accuracy (CA)\": np.mean(accuracy_scores),\n",
    "        \"F1-score\": np.mean(f1_scores),\n",
    "        \"Precision\": np.mean(precision_scores),\n",
    "        \"Recall\": np.mean(recall_scores),\n",
    "        \"MCC\": np.mean(mcc_scores)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    LogisticRegression(max_iter=10000, solver='liblinear', random_state=42),  # Increased max_iter and solver changed\n",
    "    SVC(random_state=42, probability=True),  # SVC with probability=True for AUC\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    AdaBoostClassifier(random_state=42, algorithm='SAMME'),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    Perceptron(random_state=42),\n",
    "]\n",
    "\n",
    "# Clean the data\n",
    "cleanedData = cleanData(dFrame)\n",
    "\n",
    "# Convert non-numeric data to numeric\n",
    "dFrame = changeToNumeric(cleanedData)\n",
    "\n",
    "# Split data into features and target\n",
    "X = dFrame.drop('GrainYield', axis=1)  # Assuming 'GrainYield' is the target column\n",
    "y = dFrame['GrainYield']\n",
    "\n",
    "# Initialize a list to store results\n",
    "all_results = []\n",
    "\n",
    "# Evaluate each model and store the results\n",
    "for model in models:\n",
    "    # Feature selection (RFE) for Logistic Regression (or any other model you choose)\n",
    "    if model.__class__.__name__ == 'LogisticRegression':\n",
    "        print(f\"Evaluating model {model.__class__.__name__} with feature selection...\")\n",
    "        X_rfe, selected_features = featureSelection(model, X, y)\n",
    "        print(f\"Selected Features: {selected_features}\")\n",
    "        # Evaluate on selected features\n",
    "        result_with_fs = evaluateModel(model, pd.DataFrame(X_rfe, columns=selected_features), y)\n",
    "        all_results.append(result_with_fs)\n",
    "    else:\n",
    "        print(f\"Evaluating model {model.__class__.__name__} without feature selection...\")\n",
    "        result = evaluateModel(model, X, y)\n",
    "        all_results.append(result)\n",
    "\n",
    "# Create a DataFrame to display results as a table\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Display the results\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Sort by any column, by AUC\n",
    "results_df = results_df.sort_values(by=\"AUC\", ascending=False)\n",
    "print(\"\\nSorted by AUC:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f8f08-7ead-456e-923f-d5d942871469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
